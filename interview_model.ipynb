{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "step-by-step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pdf to text\n",
    "import PyPDF2#com-working\n",
    "import re\n",
    "def pdf_to_text(pdf_path):\n",
    "    with open(pdf_path, 'rb') as file:\n",
    "        pdf_reader = PyPDF2.PdfReader(file)\n",
    "        num_pages = len(pdf_reader.pages)\n",
    "        full_text = \"\"\n",
    "        for page_num in range(num_pages):\n",
    "            page = pdf_reader.pages[page_num]\n",
    "            text = page.extract_text()\n",
    "            full_text += text\n",
    "    clean_text = re.sub(r'[^a-zA-Z0-9\\s]', '', full_text)\n",
    "    return clean_text\n",
    "pdf_path = 'resume.pdf'\n",
    "cleaned_text = pdf_to_text(pdf_path)\n",
    "resumedata=cleaned_text\n",
    "# print(pdf_resume_content)\n",
    "# result = integrate_system(pdf_resume_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.llms import OpenAI\n",
    "# from pypdf import PdfReader\n",
    "# import pandas as pd\n",
    "# import re\n",
    "# from langchain.llms.openai import OpenAI\n",
    "# from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_pdf_text(pdf_doc):\n",
    "#     text = \"\"\n",
    "#     pdf_reader = PdfReader(pdf_doc)\n",
    "#     for page in pdf_reader.pages:\n",
    "#         text += page.extract_text()\n",
    "#     return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def extract_data(pages_data):\n",
    "\n",
    "#     template = '''Extract all following values: Name,About Me,Education, Experience,Skills,Achievements,Projects,from this data: {pages}\n",
    "    \n",
    "#     Expected output : remove any dollar symbols {{'Name':'Vamsi Krishna Kumar Gompa', \n",
    "#     'About Me':'I am proficient in programming lan￾guages such as Python C and C++ and\n",
    "# have expertise in various AI frameworks\n",
    "# and libraries including TensorFlow Keras\n",
    "# and PyTorch', 'Education':'GMR Institute of Technology (GMRIT)\n",
    "# Srikakulam\n",
    "# 2021 - Present\n",
    "# B.Tech-Computer Science\n",
    "# Sri viswa\n",
    "# 2019 - 2021\n",
    "# Other Qualification-MPC\n",
    "# Sri chaitanya school\n",
    "# 2018 - 2019\n",
    "# Other Qualification-SSC\n",
    "# ', \n",
    "# 'Skills':'Python\n",
    "# Problem Solving\n",
    "# Data Structures\n",
    "# HTML\n",
    "# CSS\n",
    "# Machine Learning', \n",
    "#     'Experience':'NSIC-Data science Intern\n",
    "# 2023 - Present\n",
    "# As a data science intern I worked on data preprocessing and learned\n",
    "# few ML algorithms.Developed a Abalone age prediction using logistic\n",
    "# regression.\n",
    "# Intern studio-ML Intern\n",
    "# 2023 - Present\n",
    "# During this Internship I have learnt few unsupervised learning algo￾rithms and developed Youtube add view prediction using ml algo￾rithms.', 'Projects':'Face Rekognition\n",
    "# This project is built using deep leaning layers which reads image from\n",
    "# web page using live camera and captures the image and detect the\n",
    "# JNTU number of the student. It is also built using AWS boto3 module\n",
    "# and Flask to display JNTU number on web page.\n",
    "# Digit Recognisation\n",
    "# It is a simple linear regression model which takes input as image and\n",
    "# detect the number.\n",
    "# Face Mask Detection\n",
    "# It is built using deep learning layers which reads image of the person\n",
    "# and detects whether the person is wearing mask or not.', 'Achievements':'Elite Certificate on Python for Data science By NPTEL.\n",
    "# Certificate on Machine Learning Real world projects By Udemy.\n",
    "# Certificate on Deep Dive on Amazon Rekognition By AWS.\n",
    "# 5 start in python on Hacker Rank with a certificate.\n",
    "# Solved 250+ problems on CodeChef.',\n",
    "#     'email':'vamsikumar3u@gmail.com', 'phone number':'7416373638',\n",
    "#     'Address':'Andhra Pradesh, India'}}\n",
    "#     '''\n",
    "#     prompt_template = PromptTemplate(input_variables=['pages'], template=template)\n",
    "#     from transformers import pipeline\n",
    "# # Load the text generation pipeline\n",
    "#     generator = pipeline('text-generation', model='EleutherAI/gpt-neo-1.3B')\n",
    "# # Generate text based on your prompt\n",
    "#     generated_text = generator(prompt_template.format(pages=pages_data), max_length=200, temperature=0.7, num_return_sequences=1)\n",
    "# # Extract the generated text\n",
    "#     generated_text = generated_text[0]['generated_text']\n",
    "\n",
    "# # Print or use the generated text as needed\n",
    "#     print(generated_text)\n",
    "#     return generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_docs(user_pdf_list):\n",
    "    \n",
    "#     df = pd.DataFrame({'Name': pd.Series(dtype='str'),\n",
    "#                    'skills': pd.Series(dtype='str'),\n",
    "#                    'projects': pd.Series(dtype='str'),\n",
    "#                    'experience': pd.Series(dtype='str'),\n",
    "# \t                'education': pd.Series(dtype='str'),\n",
    "#                    'about me': pd.Series(dtype='int'),\n",
    "#                    'contact': pd.Series(dtype='str'),\n",
    "#                    'Email': pd.Series(dtype='str'),\n",
    "# \t                'Phone number': pd.Series(dtype='str'),\n",
    "#                    'Acheivements': pd.Series(dtype='str')\n",
    "#                     })\n",
    "\n",
    "#     for filename in user_pdf_list:\n",
    "        \n",
    "#         print(filename)\n",
    "#         raw_data=get_pdf_text(filename)\n",
    "#         #print(raw_data)\n",
    "#         #print(\"extracted raw data\")\n",
    "\n",
    "#         llm_extracted_data=extract_data(raw_data)\n",
    "#         #print(\"llm extracted data\")\n",
    "#         #Adding items to our list - Adding data & its metadata\n",
    "\n",
    "#         pattern = r'{(.+)}'\n",
    "#         match = re.search(pattern, llm_extracted_data, re.DOTALL)\n",
    "\n",
    "#         if match:\n",
    "#             extracted_text = match.group(1)\n",
    "#             # Converting the extracted text to a dictionary\n",
    "#             data_dict = eval('{' + extracted_text + '}')\n",
    "#             print(data_dict)\n",
    "#         else:\n",
    "#             print(\"No match found.\")\n",
    "\n",
    "        \n",
    "#         df=df.append([data_dict], ignore_index=True)\n",
    "#         print(\"********************DONE***************\")\n",
    "#         #df=df.append(save_to_dataframe(llm_extracted_data), ignore_index=True)\n",
    "\n",
    "#     df.head()\n",
    "#     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=create_docs(['resume.pdf'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trail Ends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import csv\n",
    "def extract_sections(resume_content):\n",
    "    # Define the side headings and their corresponding regular expressions\n",
    "    headings = {\n",
    "        \"Name\": r\"(\\w+\\s)+\",\n",
    "        \"Contact Details\": r\"/phone-square-alt(.+?)/envelope\",\n",
    "        \"About Me\": r\"About Me(.+?)(?=Education|$)\",\n",
    "        \"Education and Qualifications\": r\"Education(.+?)(?=Experience|$)\",\n",
    "        \"Experience\": r\"Experience(.+?)(?=Projects|$)\",\n",
    "        \"Projects\": r\"Projects(.+?)(?=Achievements|$)\",\n",
    "        \"Achievements\": r\"Achievements(.+?)$\",\n",
    "        \"Skills\": r\"Skills(.+?)(?=Experience|$)\",\n",
    "    }\n",
    "    sections = {}\n",
    "    for section, pattern in headings.items():\n",
    "        match = re.search(pattern, resume_content, re.DOTALL)\n",
    "        if match:\n",
    "            sections[section] = match.group(1).strip()\n",
    "    return sections\n",
    "def write_to_csv(data, csv_file):\n",
    "    with open(csv_file, mode='w', encoding='utf-8', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        # Write the header\n",
    "        writer.writerow([\"Section\", \"Content\"])\n",
    "        # Write data rows\n",
    "        for section, content in data.items():\n",
    "            writer.writerow([section, content])\n",
    "s=\"\"\n",
    "for i in resumedata:\n",
    "    if i=='\\n':\n",
    "        break\n",
    "    s=s+i\n",
    "resumedata=resumedata.replace('\\n',',')\n",
    "sections_data = extract_sections(resumedata)\n",
    "# Assuming you want to write the data to a CSV file named \"resume_data.csv\"\n",
    "csv_file_path = \"resume_data.csv\"\n",
    "write_to_csv(sections_data, csv_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "data=pd.read_csv(\"resume_data.csv\")\n",
    "data['Content'].iloc[0]=s\n",
    "data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content=resumedata\n",
    "sections=sections_data\n",
    "skill=data.iloc[6,1]\n",
    "skill= skill.split(',')[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 1: Import libraries  \n",
    "import spacy\n",
    "from transformers import pipeline\n",
    "# Step 2: Preprocessing\n",
    "# def extract_skills(resume):\n",
    "#     nlp = spacy.load(\"en_core_web_sm\")\n",
    "#     doc = nlp(resume)\n",
    "#     skills = [ent.text for ent in doc.ents if ent.label_ == \"SKILL\"]\n",
    "#     return skills"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_data=sections_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "import random\n",
    "def generate_random_questions(data):\n",
    "    questions = [\n",
    "        \"Tell me more about your experience with {}?\",\n",
    "        \"How did you acquire skills in {}?\",\n",
    "        \"Can you share a specific project where you utilized your skills in {}?\",\n",
    "        \"What challenges did you face while working on {}?\",\n",
    "        \"Describe your role and responsibilities in the project {}.\",\n",
    "        \"How did you stay updated with the latest trends in {}?\",\n",
    "        \"Tell me about your educational background. How did it contribute to your career in {}?\",\n",
    "        \"What motivated you to pursue {} in your education?\",\n",
    "        \"Can you provide an example of a successful project you worked on related to {}?\",\n",
    "        \"How do you handle challenges in {}?\",\n",
    "        \"Tell me about a time when your skills in {} played a crucial role in a project.\",\n",
    "        \"What is your favorite aspect of working with {}?\",\n",
    "        \"How do you approach learning new technologies or tools in {}?\",\n",
    "        \"Can you share an experience where your skills in {} made a significant impact?\",\n",
    "        \"Describe a situation where you had to apply your skills in {} to solve a problem.\",\n",
    "        \"What resources do you find most helpful for staying updated in {}?\",\n",
    "        \"How do you prioritize tasks when working on projects related to {}?\",\n",
    "        \"Tell me about a project where you had to collaborate with others in {}.\",\n",
    "        \"What advice would you give to someone starting their career in {}?\",\n",
    "        \"Describe a project that allowed you to demonstrate your expertise in {}.\"\n",
    "    ]\n",
    "    random.shuffle(questions)\n",
    "    generated_questions = [question.format(topic) for question, topic in zip(questions, data)]\n",
    "    return generated_questions\n",
    "# resume_data = {\n",
    "#     \"skills\": [\"Python\", \"Machine Learning\", \"Data Analysis\"],\n",
    "#     \"experience\": [\"Data Scientist at XYZ Corp\", \"Software Engineer at ABC Ltd\"],\n",
    "#     \"projects\": [\"Predictive Analytics Project\", \"Customer Segmentation Project\"],\n",
    "#     \"education\": [\"Master's in Computer Science\", \"Bachelor's in Engineering\"]\n",
    "# }\n",
    "random_questions = generate_random_questions(skill)\n",
    "for i, question in enumerate(random_questions, start=1):\n",
    "    print(f\"{i}. {question}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Question Generation\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "def generate_questions(skills, num_questions=5):\n",
    "    model_name = \"gpt2\"  # You can choose a different GPT-2 variant\n",
    "    model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "    tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "    questions = []\n",
    "    for skill in skills:\n",
    "        prompt = f\"What experience do you have with {skill}?\"\n",
    "        input_ids = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
    "        for _ in range(num_questions):\n",
    "            output = model.generate(input_ids, max_length=100, num_return_sequences=1, no_repeat_ngram_size=2)\n",
    "            generated_question = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "            questions.append(generated_question)\n",
    "    return questions\n",
    "# Example usage\n",
    "# skills = [\"Python\", \"Machine Learning\", \"Data Analysis\"]\n",
    "# generated_questions = generate_questions(skills)\n",
    "# for i, question in enumerate(generated_questions, start=1):\n",
    "#     print(f\"Question {i}: {question}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis and summarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: User Interaction\n",
    "def get_user_response():\n",
    "    return input(\"Please provide your response: \")\n",
    "# Step 6: Response Analysis\n",
    "def analyze_and_summarize(user_response):\n",
    "    summarizer = pipeline(\"summarization\")\n",
    "    summary = summarizer(user_response, max_length=50, min_length=5, length_penalty=2.0)[0][\"summary_text\"]\n",
    "    return summary\n",
    "def analyze_sentiment(user_response):\n",
    "    sentiment_analyzer = pipeline(\"sentiment-analysis\")\n",
    "    sentiment = sentiment_analyzer(user_response)[0]\n",
    "    return sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine all functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "def integrate_system(resume):\n",
    "    skills = extract_skills(resume)\n",
    "    questions = generate_questions(skills)\n",
    "    user_response = get_user_response()\n",
    "    summary = analyze_and_summarize(user_response)\n",
    "    sentiment = analyze_sentiment(user_response)\n",
    "    integrated_result = {\n",
    "        \"skills\": skills,\n",
    "        \"questions\": questions,\n",
    "        \"user_response\": user_response,\n",
    "        \"summary\": summary,\n",
    "        \"sentiment\": sentiment,\n",
    "    }  \n",
    "    return integrated_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = integrate_system(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PALM API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the client library and import necessary modules.\n",
    "import google.generativeai as palm\n",
    "import base64\n",
    "import json\n",
    "import pprint\n",
    "import base64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "palm.configure(api_key='AIzaSyCpta0zYFZSLw7imatVqW-exaviTfMIqu0')\n",
    "text = \"Generate 10 questions on python from interview?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'candidate_count': 1,\n",
      " 'max_output_tokens': 1024,\n",
      " 'model': 'models/text-bison-001',\n",
      " 'prompt': 'Generate 10 questions on python from interview?',\n",
      " 'safety_settings': [{'category': 'HARM_CATEGORY_DEROGATORY', 'threshold': 1},\n",
      "                     {'category': 'HARM_CATEGORY_TOXICITY', 'threshold': 1},\n",
      "                     {'category': 'HARM_CATEGORY_VIOLENCE', 'threshold': 2},\n",
      "                     {'category': 'HARM_CATEGORY_SEXUAL', 'threshold': 2},\n",
      "                     {'category': 'HARM_CATEGORY_MEDICAL', 'threshold': 2},\n",
      "                     {'category': 'HARM_CATEGORY_DANGEROUS', 'threshold': 2}],\n",
      " 'stop_sequences': [],\n",
      " 'temperature': 0.7,\n",
      " 'top_k': 40,\n",
      " 'top_p': 0.95}\n"
     ]
    }
   ],
   "source": [
    "# These parameters for the model call can be set by URL parameters.\n",
    "model = 'models/text-bison-001' # @param {isTemplate: true}\n",
    "temperature = 0.7 # @param {isTemplate: true}\n",
    "candidate_count = 1 # @param {isTemplate: true}\n",
    "top_k = 40 # @param {isTemplate: true}\n",
    "top_p = 0.95 # @param {isTemplate: true}\n",
    "max_output_tokens = 1024 # @param {isTemplate: true}\n",
    "input_bytes = text.encode('utf-8')\n",
    "encoded_bytes = base64.b64encode(input_bytes)\n",
    "text_b64= encoded_bytes.decode('utf-8')\n",
    "stop_sequences_b64 = 'W10=' # @param {isTemplate: true}\n",
    "safety_settings_b64 = 'W3siY2F0ZWdvcnkiOiJIQVJNX0NBVEVHT1JZX0RFUk9HQVRPUlkiLCJ0aHJlc2hvbGQiOjF9LHsiY2F0ZWdvcnkiOiJIQVJNX0NBVEVHT1JZX1RPWElDSVRZIiwidGhyZXNob2xkIjoxfSx7ImNhdGVnb3J5IjoiSEFSTV9DQVRFR09SWV9WSU9MRU5DRSIsInRocmVzaG9sZCI6Mn0seyJjYXRlZ29yeSI6IkhBUk1fQ0FURUdPUllfU0VYVUFMIiwidGhyZXNob2xkIjoyfSx7ImNhdGVnb3J5IjoiSEFSTV9DQVRFR09SWV9NRURJQ0FMIiwidGhyZXNob2xkIjoyfSx7ImNhdGVnb3J5IjoiSEFSTV9DQVRFR09SWV9EQU5HRVJPVVMiLCJ0aHJlc2hvbGQiOjJ9XQ==' # @param {isTemplate: true}\n",
    "# Convert the promp5t text param from a bae64 string to a string.\n",
    "text = base64.b64decode(text_b64).decode(\"utf-8\")\n",
    "# Convert the stop_sequences and safety_settings params from base64 strings to lists.\n",
    "stop_sequences = json.loads(base64.b64decode(stop_sequences_b64).decode(\"utf-8\"))\n",
    "safety_settings = json.loads(base64.b64decode(safety_settings_b64).decode(\"utf-8\"))\n",
    "defaults = {\n",
    "  'model': model,\n",
    "  'temperature': temperature,\n",
    "  'candidate_count': candidate_count,\n",
    "  'top_k': top_k,\n",
    "  'top_p': top_p,\n",
    "  'max_output_tokens': max_output_tokens,\n",
    "  'stop_sequences': stop_sequences,\n",
    "  'safety_settings': safety_settings,\n",
    "}\n",
    "# Show what will be sent with the API call.\n",
    "pprint.pprint(defaults | {'prompt': text})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. What is Python?\n",
      "2. What are the advantages of Python over other programming languages?\n",
      "3. What are the disadvantages of Python?\n",
      "4. What are the different versions of Python?\n",
      "5. What is the Python Standard Library?\n",
      "6. What are the different data types in Python?\n",
      "7. What are the different control flow statements in Python?\n",
      "8. What are the different functions in Python?\n",
      "9. What are the different modules in Python?\n",
      "10. How do you write a unit test in Python?\n"
     ]
    }
   ],
   "source": [
    "# Call the model and print the response.\n",
    "\n",
    "response = palm.generate_text(\n",
    "  **defaults,\n",
    "  prompt=text\n",
    ")\n",
    "print(response.result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Unit 1: Introduction to Computer Networks**\n",
      "\n",
      "* Topics:\n",
      "    * History of computer networks\n",
      "    * Types of computer networks\n",
      "    * Network topologies\n",
      "    * Network protocols\n",
      "    * Network addressing\n",
      "    * Network devices\n",
      "\n",
      "* Hours: 15\n",
      "\n",
      "**Unit 2: Data Communication and Networking**\n",
      "\n",
      "* Topics:\n",
      "    * Data transmission media\n",
      "    * Signal encoding\n",
      "    * Error detection and correction\n",
      "    * Flow control\n",
      "    * Congestion control\n",
      "\n",
      "* Hours: 20\n",
      "\n",
      "**Unit 3: Network Layer**\n",
      "\n",
      "* Topics:\n",
      "    * IP addressing\n",
      "    * IP routing\n",
      "    * ICMP\n",
      "    * UDP\n",
      "    * TCP\n",
      "\n",
      "* Hours: 20\n",
      "\n",
      "**Unit 4: Transport Layer**\n",
      "\n",
      "* Topics:\n",
      "    * HTTP\n",
      "    * FTP\n",
      "    * SMTP\n",
      "    * DNS\n",
      "\n",
      "* Hours: 5\n",
      "\n",
      "**Total Hours:** 60\n"
     ]
    }
   ],
   "source": [
    "response = palm.generate_text(prompt=\"design syllabus for computer networks in 4 units for 60 hours for btech computer science engineering\")\n",
    "print(response.result) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# response = palm.chat(messages=[\"Hello.\"])\n",
    "# print(response.last) #  'Hello! What can I help you with?'\n",
    "# response.reply(\"Can you tell me a joke?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
